{%- set ubuntu_id = 'u' ~ ubuntu_release.split('.')[0] %}
{%- set rocm_id = 'r' ~ rocm_version.split('.')[0] ~ rocm_version.split('.')[1] %}
{%- set libfabric_id = 'f' ~ libfabric_version.split('.')[0] ~ libfabric_version.split('.')[1] %}
{%- set mpich_id = 'm' ~ mpich_version.split('.')[0] ~ mpich_version.split('.')[1] %}
{%- set torch_id = 't' ~ torch_version.split('.')[0] ~ torch_version.split('.')[1] %}

{%- set software_digest = ubuntu_id ~ rocm_id ~ libfabric_id ~ mpich_id ~ torch_id %}
{%- set recipe_base_name = 'laifs-lumi-multitorch' %}
{%- set recipe_name = recipe_base_name ~ '-' ~ software_digest %}

name: "{{ recipe_name }}"
tag: "{{ build_tag }}"
desc: |
  This collection of container images is developed by the
  [LUMI AI Factory](https://lumi-ai-factory.eu/) and is specifically designed
  for use on the LUMI supercomputer. The images are built incrementally using
  recipes available in the LUMI AI Factory
  [GitHub repository](https://github.com/lumi-ai-factory/laifs-container-recipes).
  Each image builds on the previous one, adding new functionality, finally
  resulting in a fully featured PyTorch based ML/AI container.

  All build artifacts, including container files, build logs, and the resulting
  images, are publicly available. This allows for customization and reuse on
  other similar systems. Intermediate images are published to Docker Hub, while
  the final container images are provided on LUMI as Apptainer/Singularity `.sif`
  files under `/appl/local/laifs/containers`. The generated Containerfiles and
  other artifacts are also released as GitHub releases.

  The container release name `{{recipe_name}}-{{build_tag}}`
  encodes the following information for this image:
    - laifs: Producer of the image (LUMI AI Factory Services)
    - lumi: The primary target system for the image (LUMI)
    - multitorch: Image type (a multipurpose PyTorch image)
    - {{software_digest}}: Major software versions digest, which includes:
      - {{ubuntu_id}}: Digest for Ubuntu {{ubuntu_release}} LTS
      - {{rocm_id}}: Digest for ROCm {{rocm_version}}
      - {{libfabric_id}}: Digest for libfabric {{libfabric_version}}
      - {{mpich_id}}: Digest for MPICH {{mpich_version}}
      - {{torch_id}}: Digest for PyTorch {{torch_version}}
    - {{build_tag}}: Timestamp-based build tag

  This release includes five separate images, each building on the previous one:
    - `{{recipe_name}}-rocm-{{rocm_version}}`:
      Ubuntu base image with ROCm added
    - `{{recipe_name}}-libfabric-{{libfabric_version}}`:
      ROCm image with libfabric added
    - `{{recipe_name}}-mpich-{{mpich_version}}`:
      Libfabric image with MPICH added
    - `{{recipe_name}}-torch-{{torch_version}}`:
      MPICH image with PyTorch added
    - `{{recipe_name}}-multi`:
      MPICH image with additional AI and ML libraries

  The final image `{{recipe_name}}-multi-{{build_tag}}`
  contains these key software components:
    - Ubuntu {{ubuntu_release}} LTS (from https://hub.docker.com/layers/library/ubuntu/{{ubuntu_tag}})
    - AMD ROCm {{rocm_version}} (from {{rocm_repo}})
    - Xpmem (from {{xpmem_clone_url}} commit {{xpmem_git_commit}})
    - Cassini headers (from {{cassini_headers_source}} release tgz for {{cassini_headers_version}})
    - CXI headers (from {{cxi_headers_clone_url}} commit {{cxi_headers_git_commit}})
    - Libcxi (from {{libcxi_clone_url}} commit {{libcxi_git_commit}})
    - Libfabric {{libfabric_version}} (from {{libfabric_clone_url}} commit {{libfabric_git_commit}})
    - MPICH {{mpich_version}} (from {{mpich_source}} release tgz for {{mpich_version}})
    - AWS-OFI-RCCL {{aws_ofi_rccl_version}} (from {{aws_ofi_rccl_repo}} commit {{aws_ofi_rccl_commit}})
    - RCCL (from {{rccl_tests_repo}} commit {{rccl_tests_commit}})
    - OSU micro-benchmarks {{osu_version}} (from {{osu_source}} release tgz for {{osu_version}})
    - PyTorch {{torch_version}} (from {{torch_url}})
    - TorchVision (from {{torchvision_url}})
    - TorchAudio (from {{torchaudio_url}})
    - PyTorch Triton (from {{pytorch_triton_url}})
    - xFormers (from {{xformers_url}})
    - Apex (from {{apex_git_repo}} commit {{apex_git_commit}})
    - Bitsandbytes (from {{bitsandbytes_repo_url}} commit {{bitsandbytes_commit}})
    - Causal Conv1D (from {{causal_conv1d_repo}} commit {{causal_conv1d_commit}})
    - DeepSpeed {{deepspeed_version}} (with locally built ops addons)
    - Flash Attention (from {{flash_attention_repo_url}} commit {{flash_attention_repo_commit}})
    - vLLM {{vllm_version}} (from {{vllm_repo}} commit {{vllm_commit}})

  Documentation for each image is provided separately in the `<image name>.md`
  Markdown files. Simple Software Bill of Materials is available in the
  `<image name>.json` file, which lists all Ubuntu and PyPI packages in the
  images. Containerfiles and build logs for each image can be found in the
  `<image name>.Containerfile` and `<image name>.log` files, respectively.

steps:
  - name: {{recipe_name}}-rocm-{{rocm_version}}
    base: ubuntu:{{ubuntu_tag}}
    desc: |
      **Overview**
      This is a base image building on Ubuntu {{ubuntu_release}}LTS upstream image with ROCm
      software from AMD's official Ubuntu repositories installed on top of it. The
      image also adds a few commonly used extra Ubuntu packages and enables man pages.

      **Details**
      Ubuntu base image: ubuntu:{{ubuntu_tag}}
      AMD ROCm repository: {{rocm_repo}}
      AMD ROCm release: {{rocm_version}}
      Additional Ubuntu packages:
      {%- for pkg in extra_packages %}
        - {{ pkg }}
      {%- endfor %}
    template: rocm/Ubuntu2404_Rocm6
    force: False
    env:
      - AMDGPU_REPO={{amdgpu_repo}}
      - AMDGPU_VERSION={{amdgpu_version}}
      - ROCM_REPO={{rocm_repo}}
      - ROCM_VERSION={{rocm_version}}
      - EXTRA_LOCALES="{{extra_locales | join(' ')}}"
      - EXTRA_PACKAGES="{{extra_packages | join(' ')}}"

  - name: {{recipe_name}}-libfabric-{{libfabric_version}}
    base: {{recipe_name}}-rocm-{{rocm_version}}
    desc: |
      **Overview**
      This image builds on top of its base image by adding locally built Ubuntu
      packages to enable xpmem as well as libfabric functionality for HPE's Slingshot
      interconnect. It serves as a starting point for adding MPI capability to images
      built on top of it and can be a useful foundation for creating images with
      custom MPI stacks.

      **Details**
      Base image: {{recipe_name}}-rocm-{{rocm_version}}
      Components:
        - xpmem (from {{xpmem_clone_url}} commit {{xpmem_git_commit}})
        - Cassini headers (from {{cassini_headers_source}} release tgz for {{cassini_headers_version}})
        - CXI headers (from {{cxi_headers_clone_url}} commit {{cxi_headers_git_commit}})
        - libcxi (from {{libcxi_clone_url}} commit {{libcxi_git_commit}})
        - Libfabric {{libfabric_version}} (from {{libfabric_clone_url}} commit {{libfabric_git_commit}})
    template: libfabric/Ubuntu_Rocm_Slingshot
    force: False
    env:
      - XPMEM_CLONE_URL={{xpmem_clone_url}}
      - XPMEM_GIT_COMMIT={{xpmem_git_commit}}
      - XPMEM_VERSION={{xpmem_version}}
      - XPMEM_KERNEL_BASE_SRC={{xpmem_kernel_base_src}}
      - XPMEM_KERNEL_GENERIC_SRC={{xpmem_kernel_generic_src}}
      - XPMEM_KERNEL_ID={{xpmem_kernel_id}}
      #
      - CASSINI_HEADERS_SOURCE={{cassini_headers_source}}
      - CASSINI_HEADERS_VERSION={{cassini_headers_version}}
      #
      - CXI_HEADERS_VERSION={{cxi_headers_version}}
      - CXI_HEADERS_CLONE_URL={{cxi_headers_clone_url}}
      - CXI_HEADERS_GIT_COMMIT={{cxi_headers_git_commit}}
      #
      - LIBCXI_VERSION={{libcxi_version}}
      - LIBCXI_CLONE_URL={{libcxi_clone_url}}
      - LIBCXI_GIT_COMMIT={{libcxi_git_commit}}
      #
      - LIBFABRIC_VERSION={{libfabric_version}}
      - LIBFABRIC_CLONE_URL={{libfabric_clone_url}}
      - LIBFABRIC_GIT_COMMIT={{libfabric_git_commit}}
    export:
      name: {{recipe_name}}-libfabric-{{libfabric_version}}

  - name: {{recipe_name}}-mpich-{{mpich_version}}
    base: {{recipe_name}}-libfabric-{{libfabric_version}}
    desc: |
      **Overview**
      This image builds on top of its base image by adding an MPI library with GPU
      support, based on an MPICH build. It also includes the AWS-OFI-RCCL plugin to
      enable RCCL communication over the interconnect network using libfabric. The
      rccl-tests and OSU micro-benchmarks suite are included for performance and
      functionality validation.

      **Details**
      Base image: {{recipe_name}}-libfabric-{{libfabric_version}}
      MPI implementation: MPICH {{mpich_version}}
      Components:
        - MPICH {{mpich_version}} (from {{mpich_source}} release tgz for {{mpich_version}})
        - AWS-OFI-RCCL {{aws_ofi_rccl_version}} (from {{aws_ofi_rccl_repo}} commit {{aws_ofi_rccl_commit}})
        - RCCL (from {{rccl_tests_repo}} commit {{rccl_tests_commit}})
        - OSU micro-benchmarks {{osu_version}} (from {{osu_source}} release tgz for {{osu_version}})
    template: mpich/Ubuntu_Rocm_Slingshot
    force: False
    env:
      - AWS_OFI_RCCL_COMMIT={{aws_ofi_rccl_commit}}
      - AWS_OFI_RCCL_REPO={{aws_ofi_rccl_repo}}
      - AWS_OFI_RCCL_VERSION={{aws_ofi_rccl_version}}
      #
      - MPICH_SOURCE={{mpich_source}}
      - MPICH_VERSION={{mpich_version}}
      #
      - OSU_SOURCE={{osu_source}}
      - OSU_VERSION={{osu_version}}
      #
      - RCCL_TESTS_COMMIT={{rccl_tests_commit}}
      - RCCL_TESTS_GPU_ARCHS={{rccl_tests_gpu_archs}}
      - RCCL_TESTS_REPO={{rccl_tests_repo}}
      - RCCL_TESTS_VERSION={{rccl_tests_version}}
    export:
      name: {{recipe_name}}-mpich-{{mpich_version}}

  - name: {{recipe_name}}-torch-{{torch_version}}
    base: {{recipe_name}}-mpich-{{mpich_version}}
    desc: |
      **Overview**
      This image builds on top of its base image by adding PyTorch for AMD GPUs and
      ROCm, along with few related packages from PyTorch's upstream repositories.

      **Details**
      Base image: {{recipe_name}}-mpich-{{mpich_version}}
      PyTorch version: {{torch_version}}
      PyTorch packages and sources:
        - PyTorch: {{torch_url}}
        - TorchVision: {{torchvision_url}}
        - TorchAudio: {{torchaudio_url}}
        - PyTorch Triton: {{pytorch_triton_url}}
        - xFormers: {{xformers_url}}
    template: torch/Venv_Torch
    force: True
    env:
      - TORCH_VERSION={{torch_version}}
      #
      - PYTORCH_TRITON_URL={{pytorch_triton_url}}
      - TORCHAUDIO_URL={{torchaudio_url}}
      - TORCHVISION_URL={{torchvision_url}}
      - TORCH_URL={{torch_url}}
      - XFORMERS_URL={{xformers_url}}

  - name: {{recipe_name}}-multi
    base: {{recipe_name}}-torch-{{torch_version}}
    desc: |
      **Overview**
      This is a multipurpose ML/AI image that builds on its base image by adding a
      comprehensive selection of tools and libraries for machine learning and AI
      workloads. The image is optimized to run on LUMI but should also work on other
      systems with MI250x GPUs and Slingshot interconnect.

      **Details**
      Base image: {{recipe_name}}-torch-{{torch_version}}
      GPU architectures: {{multi_image_gpu_arch}}
      Components:
        - Apex (from {{apex_git_repo}} commit {{apex_git_commit}})
        - bitsandbytes (from {{bitsandbytes_repo_url}} commit {{bitsandbytes_commit}})
        - Causal Conv1D (from {{causal_conv1d_repo}} commit {{causal_conv1d_commit}})
        - DeepSpeed {{deepspeed_version}} (with locally built ops addons)
        - Flash Attention (from {{flash_attention_repo_url}} commit {{flash_attention_repo_commit}})
        - vLLM {{vllm_version}} (from {{vllm_repo}} commit {{vllm_commit}})

      Additional Python packages from PyPI:
        {%- for pkg in extra_pip_packages %}
        - {{pkg}}
        {%- endfor %}

      Additional Ubuntu packages:
        {%- for pkg in extra_apt_packages  %}
        - {{pkg}}
        {%- endfor %}
    template: multi/Rocm_Multipurpose
    force: False
    env:
      - APEX_GIT_REPO={{apex_git_repo}}
      - APEX_GIT_COMMIT={{apex_git_commit}}
      #
      - BITSANDBYTES_COMMIT={{bitsandbytes_commit}}
      - BITSANDBYTES_REPO_URL={{bitsandbytes_repo_url}}
      #
      - CAUSAL_CONV1D_REPO={{causal_conv1d_repo}}
      - CAUSAL_CONV1D_COMMIT={{causal_conv1d_commit}}
      #
      - DEEPSPEED_VERSION={{deepspeed_version}}
      #
      - EXTRA_APT_PACKAGES="{{extra_apt_packages | join(' ')}}"
      - EXTRA_PIP_PACKAGES="{{extra_pip_packages |Â join(' ')}}"
      #
      - FLASH_ATTENTION_REPO_COMMIT={{flash_attention_repo_commit}}
      - FLASH_ATTENTION_REPO_URL={{flash_attention_repo_url}}
      #
      - MULTI_IMAGE_GPU_ARCH={{multi_image_gpu_arch}}
      #
      - VLLM_COMMIT={{vllm_commit}}
      - VLLM_REPO={{vllm_repo}}
      #
      - WRETAG_URL={{wretag_url}}
      #
    export:
      name: {{recipe_name}}-multi
      def: |
        %runscript
        if [ "${ROCR_USE_SLURM_LOCALID}" = 1 ] && [ -n "${SLURM_LOCALID}" ]; then
            export ROCR_VISIBLE_DEVICES="$SLURM_LOCALID"
        fi
        exec "$@"
