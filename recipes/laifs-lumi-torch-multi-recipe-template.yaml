{%- set ubuntu_id = 'u' ~ ubuntu_release.split('.')[0] %}
{%- set rocm_id = 'r' ~ rocm_version.split('.')[0] ~ rocm_version.split('.')[1] %}
{%- set libfabric_id = 'f' ~ libfabric_version.split('.')[0] ~ libfabric_version.split('.')[1] %}
{%- set mpich_id = 'm' ~ mpich_version.split('.')[0] ~ mpich_version.split('.')[1] %}
{%- set torch_id = 't' ~ torch_version.split('.')[0] ~ torch_version.split('.')[1] %}

{%- set software_digest = ubuntu_id ~ rocm_id ~ libfabric_id ~ mpich_id ~ torch_id %}
{%- set recipe_base_name = 'laifs-lumi-multitorch' %}
{%- set recipe_name = recipe_base_name ~ '-' ~ software_digest %}

name: "{{ recipe_name }}"
digest: "{{ software_digest }}"
tag: "{{ build_tag }}"
desc: |
  This collection of container images is developed by the
  [LUMI AI Factory](https://lumi-ai-factory.eu/) and is specifically designed
  for use on the LUMI supercomputer. The images are built incrementally using
  recipes available in the LUMI AI Factory
  [GitHub repository](https://github.com/lumi-ai-factory/laifs-container-recipes).
  Each image builds on the previous one, adding new functionality, finally
  resulting in a fully featured PyTorch based ML/AI container.

  All build artifacts, including container files, build logs, and the resulting
  images, are publicly available. This allows for customization and reuse on
  other similar systems. Intermediate images are published to Docker Hub, while
  the final container images are provided on LUMI as Apptainer/Singularity `.sif`
  files under `/appl/local/laifs/containers`. The generated Containerfiles and
  other artifacts are released as GitHub releases.

  The GitHub release consists of:
  - A `.yaml` recipe file which defines the build steps, software versions, and
    includes all required Containerfiles and documentation to reproduce the build
    of this container image release using the accompanied build scripts.
  - Containerfiles and Singularity definition files (`.Containerfile`, `.def`) for
    convenience (this data is embedded in the `.yaml` recipe as well).
  - This release README file and separate per-image documentation (`.md`).
  - Build logs (`.log`) and SBOM files (`.json`) for all images for transparency.

  On Docker Hub the images are available with the following tag/naming scheme:
    - Floating tags for latest version:
      - `lumi-ai-factory/lumi-multitorch:full` (latest complete full image across all variants)
      - `lumi-ai-factory/lumi-multitorch:torch` (latest PyTorch build across all variants)
      - `lumi-ai-factory/lumi-multitorch:mpich` (latest MPICH build across all variants)
      - `lumi-ai-factory/lumi-multitorch:libfabric` (latest Libfabric build across all variants)
      - `lumi-ai-factory/lumi-multitorch:rocm` (latest ROCm build across all variants)
    - Floating tags for latest version with specific versions variant:
      - `lumi-ai-factory/lumi-multitorch:full-{{software_digest}}-latest` (latest
        build for this software stack, see the release name information below for details
        about the software digest part "{{software_digest}}")
      - The same scheme is also available for the torch, mpich, libfabric and rocm images.
    - Build-specific tags for reproducibility:
      - `lumi-ai-factory/lumi-multitorch:full-{{software_digest}}-{{build_tag}}` (specific pinned build of the full image)
      - `lumi-ai-factory/lumi-multitorch:torch-{{software_digest}}-{{build_tag}}` (specific pinned build of the torch image)
      - Tags with the same same scheme are also available for the mpich, libfabric and rocm images.
    - Example Docker Hub pull commands:
      - `docker pull lumi-ai-factory/lumi-multitorch:full-{{software_digest}}-{{build_tag}}`
      - `docker pull lumi-ai-factory/lumi-multitorch:mpich-{{software_digest}}-latest`
      - `docker pull lumi-ai-factory/lumi-multitorch:rocm`

  The images are also available to be used directly on LUMI:
    - Path to this release on LUMI:
      - `/appl/local/laifs/containers/laifs-lumi-multitorch-{{software_digest}}-{{build_tag}}/`
    - Example symlink paths to the images on LUMI:
      - `/appl/local/laifs/containers/laifs-lumi-multitorch-{{software_digest}}-latest/`
      - `/appl/local/laifs/containers/laifs-lumi-multitorch-latest/`
    - Example release dicectory content on LUMI:
      - `laifs-lumi-multitorch-{{software_digest}}-{{build_tag}}.md`: The main readme file
      - `laifs-lumi-multitorch-{{software_digest}}-full-{{build_tag}}.sif`: Singularity image for the main image
      - `laifs-lumi-multitorch-{{software_digest}}-full-{{build_tag}}.md`: Readme file for the main image
      - `laifs-lumi-multitorch-{{software_digest}}-full-{{build_tag}}.json`: Software Bill of materials for the main image
      - `laifs-lumi-multitorch-{{software_digest}}-torch-{{build_tag}}.sif`: Singularity image for the torch image
      - `laifs-lumi-multitorch-{{software_digest}}-torch-{{build_tag}}.md`: Readme file for the torch image
      - `laifs-lumi-multitorch-{{software_digest}}-torch-{{build_tag}}.json`: Software Bill of materials for the torch image
      - `...`
    - Example usage on LUMI: `singularity run ...`

  The container release name `{{recipe_name}}-{{build_tag}}`
  encodes the following information for this image:
    - laifs: Producer of the image (LUMI AI Factory Services)
    - lumi: The primary target system for the image (LUMI)
    - multitorch: Image type (a multipurpose PyTorch image)
    - {{software_digest}}: Major software versions digest, which includes:
      - {{ubuntu_id}}: Digest for Ubuntu {{ubuntu_release}} LTS
      - {{rocm_id}}: Digest for ROCm {{rocm_version}}
      - {{libfabric_id}}: Digest for libfabric {{libfabric_version}}
      - {{mpich_id}}: Digest for MPICH {{mpich_version}}
      - {{torch_id}}: Digest for PyTorch {{torch_version}}
    - {{build_tag}}: Timestamp-based build tag

  This release includes five separate images, each building on the previous one:
    - `{{recipe_name}}-rocm`:
      Ubuntu base image with ROCm-{{rocm_version}} added
    - `{{recipe_name}}-libfabric`:
      ROCm image with libfabric {{libfabric_version}} added
    - `{{recipe_name}}-mpich-`:
      Libfabric image with MPICH {{mpich_version}} added
    - `{{recipe_name}}-torch`:
      MPICH image with PyTorch {{torch_version}} added
    - `{{recipe_name}}-full`:
      PyTorch image with selection of AI and ML libraries added

  The final image `{{recipe_name}}-full-{{build_tag}}`
  contains these key software components:
    - Ubuntu {{ubuntu_release}} LTS (from https://hub.docker.com/layers/library/ubuntu/{{ubuntu_tag}})
    - AMD ROCm {{rocm_version}} (from {{rocm_repo}})
    - Xpmem (from {{xpmem_clone_url}} commit {{xpmem_git_commit}})
    - Cassini headers (from {{cassini_headers_source}} release tgz for {{cassini_headers_version}})
    - CXI headers (from {{cxi_headers_clone_url}} commit {{cxi_headers_git_commit}})
    - Libcxi (from {{libcxi_clone_url}} commit {{libcxi_git_commit}})
    - Libfabric {{libfabric_version}} (from {{libfabric_clone_url}} commit {{libfabric_git_commit}})
    - MPICH {{mpich_version}} (from {{mpich_source}} release tgz for {{mpich_version}})
    - AWS-OFI-RCCL {{aws_ofi_rccl_version}} (from {{aws_ofi_rccl_repo}} commit {{aws_ofi_rccl_commit}})
    - RCCL (from {{rccl_tests_repo}} commit {{rccl_tests_commit}})
    - OSU micro-benchmarks {{osu_version}} (from {{osu_source}} release tgz for {{osu_version}})
    - PyTorch {{torch_version}} (from {{torch_url}})
    - TorchVision (from {{torchvision_url}})
    - TorchAudio (from {{torchaudio_url}})
    - PyTorch Triton (from {{pytorch_triton_url}})
    - xFormers (from {{xformers_url}})
    - Apex (from {{apex_git_repo}} commit {{apex_git_commit}})
    - Bitsandbytes (from {{bitsandbytes_repo_url}} commit {{bitsandbytes_commit}})
    - Causal Conv1D (from {{causal_conv1d_repo}} commit {{causal_conv1d_commit}})
    - DeepSpeed {{deepspeed_version}} (with locally built ops addons)
    - Flash Attention (from {{flash_attention_repo_url}} commit {{flash_attention_repo_commit}})
    - vLLM {{vllm_version}} (from {{vllm_repo}} commit {{vllm_commit}})

  Documentation for each image is provided separately in the `<image name>.md`
  Markdown files. Simple Software Bill of Materials is available in the
  `<image name>.json` file, which lists all Ubuntu and PyPI packages in the
  images. Containerfiles and build logs for each image can be found in the
  `<image name>.Containerfile` and `<image name>.log` files, respectively.

steps:
  - name: {{recipe_name}}-rocm
    base: ubuntu:{{ubuntu_tag}}
    desc: |
      **Overview**
      This is a base image building on Ubuntu {{ubuntu_release}} LTS upstream image with ROCm
      software from AMD's official Ubuntu repositories installed on top of it. The
      image also adds a few commonly used extra Ubuntu packages and enables man pages.

      **Details**
      Ubuntu base image: ubuntu:{{ubuntu_tag}}
      AMD ROCm repository: {{rocm_repo}}
      AMD ROCm release: {{rocm_version}}
      Additional Ubuntu packages:
      {%- for pkg in extra_packages %}
        - {{ pkg }}
      {%- endfor %}
    template: rocm/Ubuntu2404_Rocm6
    force: False
    env:
      - AMDGPU_REPO={{amdgpu_repo}}
      - AMDGPU_VERSION={{amdgpu_version}}
      - ROCM_REPO={{rocm_repo}}
      - ROCM_VERSION={{rocm_version}}
      - EXTRA_LOCALES="{{extra_locales | join(' ')}}"
      - EXTRA_PACKAGES="{{extra_packages | join(' ')}}"
    export:
      name: {{recipe_name}}-rocm

  - name: {{recipe_name}}-libfabric
    base: {{recipe_name}}-rocm
    desc: |
      **Overview**
      This image builds on top of its base image by adding locally built Ubuntu
      packages to enable xpmem as well as libfabric functionality for HPE's Slingshot
      interconnect. It serves as a starting point for adding MPI capability to images
      built on top of it and can be a useful foundation for creating images with
      custom MPI stacks.

      **Details**
      Base image: {{recipe_name}}-rocm
      Components:
        - xpmem (from {{xpmem_clone_url}} commit {{xpmem_git_commit}})
        - Cassini headers (from {{cassini_headers_source}} release tgz for {{cassini_headers_version}})
        - CXI headers (from {{cxi_headers_clone_url}} commit {{cxi_headers_git_commit}})
        - libcxi (from {{libcxi_clone_url}} commit {{libcxi_git_commit}})
        - Libfabric {{libfabric_version}} (from {{libfabric_clone_url}} commit {{libfabric_git_commit}})
    template: libfabric/Ubuntu_Rocm_Slingshot
    force: False
    env:
      - XPMEM_CLONE_URL={{xpmem_clone_url}}
      - XPMEM_GIT_COMMIT={{xpmem_git_commit}}
      - XPMEM_VERSION={{xpmem_version}}
      - XPMEM_KERNEL_BASE_SRC={{xpmem_kernel_base_src}}
      - XPMEM_KERNEL_GENERIC_SRC={{xpmem_kernel_generic_src}}
      - XPMEM_KERNEL_ID={{xpmem_kernel_id}}
      #
      - CASSINI_HEADERS_SOURCE={{cassini_headers_source}}
      - CASSINI_HEADERS_VERSION={{cassini_headers_version}}
      #
      - CXI_HEADERS_VERSION={{cxi_headers_version}}
      - CXI_HEADERS_CLONE_URL={{cxi_headers_clone_url}}
      - CXI_HEADERS_GIT_COMMIT={{cxi_headers_git_commit}}
      #
      - LIBCXI_VERSION={{libcxi_version}}
      - LIBCXI_CLONE_URL={{libcxi_clone_url}}
      - LIBCXI_GIT_COMMIT={{libcxi_git_commit}}
      #
      - LIBFABRIC_VERSION={{libfabric_version}}
      - LIBFABRIC_CLONE_URL={{libfabric_clone_url}}
      - LIBFABRIC_GIT_COMMIT={{libfabric_git_commit}}
    export:
      name: {{recipe_name}}-libfabric

  - name: {{recipe_name}}-mpich
    base: {{recipe_name}}-libfabric
    desc: |
      **Overview**
      This image builds on top of its base image by adding an MPI library with GPU
      support, based on an MPICH build. It also includes the AWS-OFI-RCCL plugin to
      enable RCCL communication over the interconnect network using libfabric. The
      rccl-tests and OSU micro-benchmarks suite are included for performance and
      functionality validation.

      **Details**
      Base image: {{recipe_name}}-libfabric
      MPI implementation: MPICH {{mpich_version}}
      Components:
        - MPICH {{mpich_version}} (from {{mpich_source}} release tgz for {{mpich_version}})
        - AWS-OFI-RCCL {{aws_ofi_rccl_version}} (from {{aws_ofi_rccl_repo}} commit {{aws_ofi_rccl_commit}})
        - RCCL (from {{rccl_tests_repo}} commit {{rccl_tests_commit}})
        - OSU micro-benchmarks {{osu_version}} (from {{osu_source}} release tgz for {{osu_version}})
    template: mpich/Ubuntu_Rocm_Slingshot
    force: False
    env:
      - AWS_OFI_RCCL_COMMIT={{aws_ofi_rccl_commit}}
      - AWS_OFI_RCCL_REPO={{aws_ofi_rccl_repo}}
      - AWS_OFI_RCCL_VERSION={{aws_ofi_rccl_version}}
      #
      - MPICH_SOURCE={{mpich_source}}
      - MPICH_VERSION={{mpich_version}}
      #
      - OSU_SOURCE={{osu_source}}
      - OSU_VERSION={{osu_version}}
      #
      - RCCL_TESTS_COMMIT={{rccl_tests_commit}}
      - RCCL_TESTS_GPU_ARCHS={{rccl_tests_gpu_archs}}
      - RCCL_TESTS_REPO={{rccl_tests_repo}}
      - RCCL_TESTS_VERSION={{rccl_tests_version}}
    export:
      name: {{recipe_name}}-mpich

  - name: {{recipe_name}}-torch
    base: {{recipe_name}}-mpich
    desc: |
      **Overview**
      This image builds on top of its base image by adding PyTorch for AMD GPUs and
      ROCm, along with few related packages from PyTorch's upstream repositories.

      **Details**
      Base image: {{recipe_name}}-mpich
      PyTorch version: {{torch_version}}
      PyTorch packages and sources:
        - PyTorch: {{torch_url}}
        - TorchVision: {{torchvision_url}}
        - TorchAudio: {{torchaudio_url}}
        - PyTorch Triton: {{pytorch_triton_url}}
        - xFormers: {{xformers_url}}
    template: torch/Venv_Torch
    force: True
    env:
      - TORCH_VERSION={{torch_version}}
      #
      - PYTORCH_TRITON_URL={{pytorch_triton_url}}
      - TORCHAUDIO_URL={{torchaudio_url}}
      - TORCHVISION_URL={{torchvision_url}}
      - TORCH_URL={{torch_url}}
      - XFORMERS_URL={{xformers_url}}
    export:
      name: {{recipe_name}}-torch

  - name: {{recipe_name}}-full
    base: {{recipe_name}}-torch
    desc: |
      **Overview**
      This is a multipurpose ML/AI image that builds on its base image by adding a
      comprehensive selection of tools and libraries for machine learning and AI
      workloads. The image is optimized to run on LUMI but should also work on other
      systems with MI250x GPUs and Slingshot interconnect.

      **Details**
      Base image: {{recipe_name}}-torch
      GPU architectures: {{multi_image_gpu_arch}}
      Components:
        - Apex (from {{apex_git_repo}} commit {{apex_git_commit}})
        - bitsandbytes (from {{bitsandbytes_repo_url}} commit {{bitsandbytes_commit}})
        - Causal Conv1D (from {{causal_conv1d_repo}} commit {{causal_conv1d_commit}})
        - DeepSpeed {{deepspeed_version}} (with locally built ops addons)
        - Flash Attention (from {{flash_attention_repo_url}} commit {{flash_attention_repo_commit}})
        - vLLM {{vllm_version}} (from {{vllm_repo}} commit {{vllm_commit}})

      Additional Python packages from PyPI:
        {%- for pkg in extra_pip_packages %}
        - {{pkg}}
        {%- endfor %}

      Additional Ubuntu packages:
        {%- for pkg in extra_apt_packages  %}
        - {{pkg}}
        {%- endfor %}
    template: multi/Rocm_Multipurpose
    force: False
    env:
      - APEX_GIT_REPO={{apex_git_repo}}
      - APEX_GIT_COMMIT={{apex_git_commit}}
      #
      - BITSANDBYTES_COMMIT={{bitsandbytes_commit}}
      - BITSANDBYTES_REPO_URL={{bitsandbytes_repo_url}}
      #
      - CAUSAL_CONV1D_REPO={{causal_conv1d_repo}}
      - CAUSAL_CONV1D_COMMIT={{causal_conv1d_commit}}
      #
      - DEEPSPEED_VERSION={{deepspeed_version}}
      #
      - EXTRA_APT_PACKAGES="{{extra_apt_packages | join(' ')}}"
      - EXTRA_PIP_PACKAGES="{{extra_pip_packages |Â join(' ')}}"
      #
      - FLASH_ATTENTION_REPO_COMMIT={{flash_attention_repo_commit}}
      - FLASH_ATTENTION_REPO_URL={{flash_attention_repo_url}}
      #
      - MULTI_IMAGE_GPU_ARCH={{multi_image_gpu_arch}}
      #
      - VLLM_COMMIT={{vllm_commit}}
      - VLLM_REPO={{vllm_repo}}
      #
      - WRETAG_URL={{wretag_url}}
      #
    export:
      name: {{recipe_name}}-full
      def: |
        %runscript
        if [ "${ROCR_USE_SLURM_LOCALID}" = 1 ] && [ -n "${SLURM_LOCALID}" ]; then
            export ROCR_VISIBLE_DEVICES="$SLURM_LOCALID"
        fi
        exec "$@"
post: |
  podman run -it --rm {{recipe_name}}-full:{{build_tag}} cat /.sbom.json > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-full-{{build_tag}}.json
  podman run -it --rm {{recipe_name}}-mpich:{{build_tag}} cat /.sbom.json > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-mpich-{{build_tag}}.json
  podman run -it --rm {{recipe_name}}-rocm-{{rocm_version}}:{{build_tag}} cat /.sbom.json > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-rocm-{{rocm_version}}-{{build_tag}}.json
  podman run -it --rm {{recipe_name}}-libfabric-{{libfabric}}:{{build_tag}} cat /.sbom.json > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-libfabric-{{libfabric}}-{{build_tag}}.json
  podman run -it --rm {{recipe_name}}-torch:{{build_tag}} cat /.sbom.json > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-torch-{{build_tag}}.json
  sha256sum builds/{{recipe_name}}-{{build_tag}}/* > builds/{{recipe_name}}-{{build_tag}}/{{recipe_name}}-full-{{build_tag}}.sha256
