@@ BUILD_ARGS @@

FROM $BASE_IMAGE:$BASE_IMAGE_TAG

ARG APEX_GIT_REPO
ARG APEX_GIT_COMMIT
ARG APEX_BUILD_ARCHS

ARG BASE_IMAGE
ARG BASE_IMAGE_TAG

ARG BITSANDBYTES_COMMIT
ARG BITSANDBYTES_GPU_ARCHS
ARG BITSANDBYTES_REPO_URL

ARG CAUSAL_CONV1D_ARCHS
ARG CAUSAL_CONV1D_COMMIT
ARG CAUSAL_CONV1D_REPO

ARG EXTRA_APT_PACKAGES
ARG EXTRA_PIP_PACKAGES

ARG FLASH_ATTENTION_GPU_ARCHS
ARG FLASH_ATTENTION_REPO_COMMIT
ARG FLASH_ATTENTION_REPO_URL

ARG VLLM_COMMIT
ARG VLLM_GPU_ARCHS

ARG XFORMERS_PIP_URL


#
# Install required pre-built pip and apt packages
#
RUN set -ue; \
  python3.12 -m venv /opt/venv; \
  . /opt/venv/bin/activate; \
  apt-get -y --no-install-recommends install ${EXTRA_APT_PACKAGES}; \
  apt clean ;\
  pip install ${EXTRA_PIP_PACKAGES};


#
# Install bitsandbytes for ROCm
#
RUN set -ue; \
  mkdir /opt/src; \
  . /opt/venv/bin/activate; \
  git clone ${BITSANDBYTES_REPO_URL} /opt/src/bitsandbytes; \
  cd /opt/src/bitsandbytes; \
  git checkout ${BITSANDBYTES_COMMIT}; \
  cmake -DCOMPUTE_BACKEND=hip -DGPU_TARGETS=${BITSANDBYTES_GPU_ARCHS} -DBNB_ROCM_ARCH=${BITSANDBYTES_GPU_ARCHS} -S .; \
  make; \
  pip install .; \
  cd / && rm -rf /opt/src/bitsandbytes;


#
# Compile and install Flash Attention
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  git clone $FLASH_ATTENTION_REPO_URL /opt/src/flash-attention; \
  cd /opt/src/flash-attention; \
  git checkout $FLASH_ATTENTION_REPO_COMMIT; \
  BUILD_TARGET=rocm MAX_JOBS=$(nproc) GPU_ARCHS=$FLASH_ATTENTION_GPU_ARCHS python3 setup.py bdist_wheel --dist-dir=dist; \
  pip install /opt/src/flash-attention/dist/*.whl; \
  cd / && rm -rf /opt/src/flash-attention;


#
# Install xFormers
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  pip install xformers --index-url $XFORMERS_PIP_URL;


#
# Install causal-conv1d
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  git clone $CAUSAL_CONV1D_REPO /opt/src/causal-conv1d; \
  cd /opt/src/causal-conv1d; \
  cd causal-conv1d; \
  export PYTORCH_ROCM_ARCH_OVERRIDE="${CAUSAL_CONV1D_ARCHS}"; \
  export HIP_ARCHITECTURES="${CAUSAL_CONV1D_ARCHS}"; \
  pip install --no-build-isolation .; \
  rm -rf /opt/src/causal-conv1d;


#
# Install Apex
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  git clone "${APEX_GIT_REPO}" /opt/src/apex;\
  cd /opt/src/apex; \
  git checkout "${APEX_GIT_COMMIT}"; \
  export PYTORCH_ROCM_ARCH="${APEX_BUILD_ARCHS}"; \
  pip install -v --disable-pip-version-check --no-cache-dir --no-build-isolation --config-settings "--build-option=--cpp_ext" --config-settings "--build-option=--cuda_ext" ./; \
  cd / && rm -rf /opt/src/apex;


#
# Compile and install vLLM
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  git clone https://github.com/vllm-project/vllm.git /opt/src/vllm; \
  cd /opt/rocm/share/amd_smi; \
  python3 -m pip install .; \
  cd /opt/src/vllm; \
  git fetch --tags; \
  git checkout $VLLM_COMMIT; \
  export GPU_ARCHS=$VLLM_GPU_ARCHS; \
  export PYTORCH_ROCM_ARCH=$VLLM_GPU_ARCHS; \
  export GPU_TARGETS=$VLLM_GPU_ARCHS; \
  export MAKEFLAGS="-j$(nproc)"; \
  python3 setup.py clean --all; \
  python3 setup.py bdist_wheel --dist-dir=dist; \
  pip install ./dist/*.whl;
  cd / && rm -rf /opt/src/vllm;


#
# Install Deepspeed (revisit: The ops are currently not getting built, likely because of issue in the DS v0.18.1 release)
#
RUN set -ue; \
  . /opt/venv/bin/activate; \
  export DS_BUILD_OPS=1; \
  python3 -m pip install deepspeed --no-build-isolation;


ENV PATH="/opt/venv/bin:$PATH"

CMD ["/bin/bash"]
